{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3.8 Read write Excel files\n",
    "\n",
    "Spark does not have built in connector to read Excel file directly. But there are third party connector\n",
    "- https://mvnrepository.com/artifact/com.crealytics/spark-excel\n",
    "\n",
    "With pyspark, the best way is to use pandas to read the excel then convert it back to spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType\n",
    "from pyspark.sql.functions import lit, col, when, concat, udf\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/09 10:55:49 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.184.146 instead (on interface ens33)\n",
      "22/08/09 10:55:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/08/09 10:55:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "local=True\n",
    "if local:\n",
    "    spark=SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"ReadExcelFiles\")\\\n",
    "                  .getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"ReadExcelFiles\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",os.environ['IMAGE_NAME']) \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"8g\") \\\n",
    "                      .config('spark.jars.packages','com.crealytics:spark-excel_2.12:3.1.2_0.17.1') \\\n",
    "                      .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "file_path=\"../../../data/per.xls\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.8.1 Use third party excel connector\n",
    "\n",
    "\n",
    "In my local environment, I use the spark 3.1.x. So I use the below jar as the\n",
    "```xml\n",
    "<!-- https://mvnrepository.com/artifact/com.crealytics/spark-excel -->\n",
    "<dependency>\n",
    "    <groupId>com.crealytics</groupId>\n",
    "    <artifactId>spark-excel_2.12</artifactId>\n",
    "    <version>3.1.2_0.17.1</version>\n",
    "</dependency>\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 3.8.2 Use standalone pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.8.3 Use pandas on spark\n",
    "\n",
    "**Note: With spark 3.1.1, the pandas on spark has problem with types when converting pandas df to spark df. So use stand-alone pandas is\n",
    "recommended**\n",
    "It requires a dependency 'xlrd', you need to install in on your python virtual env.\n",
    "\n",
    "```shell\n",
    "pip install xlrd\n",
    "poety add xlrd\n",
    "```\n",
    "\n",
    "Note the function read_excel returns a pandas dataframe not a spark dataframe. You need to convert it explicitly back to spark dataframe.\n",
    "\n",
    "For more detail about read_excel, read the official [doc](https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.read_excel.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pliu/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/pandas/namespace.py:1078: FutureWarning: convert_float is deprecated and will be removed in a future version\n",
      "  return pd.read_excel(\n"
     ]
    }
   ],
   "source": [
    "df=ps.read_excel(file_path, sheet_name='per', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Assureur/Support  Avis sur 5  Frais Vers.  Frais Gestion Fonds ?  Frais Gestion UC  Frais/rente                   Fonds euros  Taux brut  Nombre SCPI  Nombre SCI  Nombre OPCI  Nombre ETF  Nombre UC\nPER                                                                                                                                                                                                                                                  \nABEILLE RETRAITE PLURIELLE      ABEILLE RETRAITE PROFESSIONNELLE         NaN          5.0                   1.00              1.00          NaN             ABEILLE EURO PERP        NaN            0           0            0           0         80\nAFER RETRAITE INDIVIDUELLE                               ABEILLE         NaN          3.0                   1.00              1.00          0.0  ABEILLE RP SECURITE RETRAITE        NaN            0           0            0           0         80\nALLIANZ PER HORIZON                                      ALLIANZ         NaN          4.8                   0.85              0.85          NaN              ALLIANZ RETRAITE        NaN            0           0            0           0         92\nAMBITION RETRAITE INDIVIDUELLE                       LA MONDIALE         NaN          3.9                   0.70              0.70          0.0          FONDS EUROS RETRAITE        NaN            0           0            0           0          0\nAMPLI-PER LIBERTE                                 AMPLI-MUTUELLE         NaN          0.0                   0.50              0.40          0.0               AMPLI PER EUROS        NaN            2           0            0           3          4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Assureur/Support</th>\n      <th>Avis sur 5</th>\n      <th>Frais Vers.</th>\n      <th>Frais Gestion Fonds ?</th>\n      <th>Frais Gestion UC</th>\n      <th>Frais/rente</th>\n      <th>Fonds euros</th>\n      <th>Taux brut</th>\n      <th>Nombre SCPI</th>\n      <th>Nombre SCI</th>\n      <th>Nombre OPCI</th>\n      <th>Nombre ETF</th>\n      <th>Nombre UC</th>\n    </tr>\n    <tr>\n      <th>PER</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ABEILLE RETRAITE PLURIELLE</th>\n      <td>ABEILLE RETRAITE PROFESSIONNELLE</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>NaN</td>\n      <td>ABEILLE EURO PERP</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>AFER RETRAITE INDIVIDUELLE</th>\n      <td>ABEILLE</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>ABEILLE RP SECURITE RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>ALLIANZ PER HORIZON</th>\n      <td>ALLIANZ</td>\n      <td>NaN</td>\n      <td>4.8</td>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>NaN</td>\n      <td>ALLIANZ RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>AMBITION RETRAITE INDIVIDUELLE</th>\n      <td>LA MONDIALE</td>\n      <td>NaN</td>\n      <td>3.9</td>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>0.0</td>\n      <td>FONDS EUROS RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>AMPLI-PER LIBERTE</th>\n      <td>AMPLI-MUTUELLE</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>AMPLI PER EUROS</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# use pandas dataframe function to write csv\n",
    "path=\"/tmp/spark\"\n",
    "df.to_csv(\n",
    "    path=r'%s/excel_output' % path,\n",
    "    index_col=[\"PER_name\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pandas requires an engine to write excel (xlswriter), so you need to install it in your python virtual env\n",
    "\n",
    "```shell\n",
    "pip install xlsxwriter\n",
    "poetry add xlsxwriter\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# use pandas dataframe function to write excel\n",
    "#\n",
    "df.to_excel(r'%s/excel_output.xlsx' % path, sheet_name='PER',engine='xlsxwriter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}