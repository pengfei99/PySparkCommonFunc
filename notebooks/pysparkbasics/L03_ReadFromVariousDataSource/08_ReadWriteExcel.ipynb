{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3.8 Read write Excel files\n",
    "\n",
    "Spark does not have built in connector to read Excel file directly. But there are third party connector\n",
    "- https://mvnrepository.com/artifact/com.crealytics/spark-excel\n",
    "\n",
    "With pyspark, the best way is to use pandas to read the excel then convert it back to spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType\n",
    "from pyspark.sql.functions import lit, col, when, concat, udf\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/09 10:55:49 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.184.146 instead (on interface ens33)\n",
      "22/08/09 10:55:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/08/09 10:55:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "local=True\n",
    "if local:\n",
    "    spark=SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"ReadExcelFiles\")\\\n",
    "                  .getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"ReadExcelFiles\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",os.environ['IMAGE_NAME']) \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"8g\") \\\n",
    "                      .config('spark.jars.packages','com.crealytics:spark-excel_2.12:3.1.2_0.17.1') \\\n",
    "                      .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "file_path=\"../../../data/per.xls\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.8.1 Use third party excel connector\n",
    "\n",
    "\n",
    "In my local environment, I use the spark 3.1.x. So I use the below jar as the\n",
    "```xml\n",
    "<!-- https://mvnrepository.com/artifact/com.crealytics/spark-excel -->\n",
    "<dependency>\n",
    "    <groupId>com.crealytics</groupId>\n",
    "    <artifactId>spark-excel_2.12</artifactId>\n",
    "    <version>3.1.2_0.17.1</version>\n",
    "</dependency>\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 3.8.2 Use standalone pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.8.3 Use pandas on spark\n",
    "\n",
    "It requires a dependency 'xlrd', you need to install in on your python virtual env.\n",
    "\n",
    "```shell\n",
    "pip install xlrd\n",
    "poety add xlrd\n",
    "```\n",
    "\n",
    "Note the function read_excel returns a pandas dataframe not a spark dataframe. You need to convert it explicitly back to spark dataframe.\n",
    "\n",
    "For more detail about read_excel, read the official [doc](https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.read_excel.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pliu/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/pandas/namespace.py:1078: FutureWarning: convert_float is deprecated and will be removed in a future version\n",
      "  return pd.read_excel(\n"
     ]
    }
   ],
   "source": [
    "df=ps.read_excel(file_path, sheet_name='per', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Assureur/Support  Avis sur 5  Frais Vers.  Frais Gestion Fonds ?  Frais Gestion UC  Frais/rente                   Fonds euros  Taux brut  Nombre SCPI  Nombre SCI  Nombre OPCI  Nombre ETF  Nombre UC\nPER                                                                                                                                                                                                                                                  \nABEILLE RETRAITE PLURIELLE      ABEILLE RETRAITE PROFESSIONNELLE         NaN          5.0                   1.00              1.00          NaN             ABEILLE EURO PERP        NaN            0           0            0           0         80\nAFER RETRAITE INDIVIDUELLE                               ABEILLE         NaN          3.0                   1.00              1.00          0.0  ABEILLE RP SECURITE RETRAITE        NaN            0           0            0           0         80\nALLIANZ PER HORIZON                                      ALLIANZ         NaN          4.8                   0.85              0.85          NaN              ALLIANZ RETRAITE        NaN            0           0            0           0         92\nAMBITION RETRAITE INDIVIDUELLE                       LA MONDIALE         NaN          3.9                   0.70              0.70          0.0          FONDS EUROS RETRAITE        NaN            0           0            0           0          0\nAMPLI-PER LIBERTE                                 AMPLI-MUTUELLE         NaN          0.0                   0.50              0.40          0.0               AMPLI PER EUROS        NaN            2           0            0           3          4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Assureur/Support</th>\n      <th>Avis sur 5</th>\n      <th>Frais Vers.</th>\n      <th>Frais Gestion Fonds ?</th>\n      <th>Frais Gestion UC</th>\n      <th>Frais/rente</th>\n      <th>Fonds euros</th>\n      <th>Taux brut</th>\n      <th>Nombre SCPI</th>\n      <th>Nombre SCI</th>\n      <th>Nombre OPCI</th>\n      <th>Nombre ETF</th>\n      <th>Nombre UC</th>\n    </tr>\n    <tr>\n      <th>PER</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ABEILLE RETRAITE PLURIELLE</th>\n      <td>ABEILLE RETRAITE PROFESSIONNELLE</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>NaN</td>\n      <td>ABEILLE EURO PERP</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>AFER RETRAITE INDIVIDUELLE</th>\n      <td>ABEILLE</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>ABEILLE RP SECURITE RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>ALLIANZ PER HORIZON</th>\n      <td>ALLIANZ</td>\n      <td>NaN</td>\n      <td>4.8</td>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>NaN</td>\n      <td>ALLIANZ RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>AMBITION RETRAITE INDIVIDUELLE</th>\n      <td>LA MONDIALE</td>\n      <td>NaN</td>\n      <td>3.9</td>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>0.0</td>\n      <td>FONDS EUROS RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>AMPLI-PER LIBERTE</th>\n      <td>AMPLI-MUTUELLE</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>AMPLI PER EUROS</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# use pandas dataframe function to write csv\n",
    "path=\"/tmp/spark\"\n",
    "df.to_csv(\n",
    "    path=r'%s/excel_output' % path,\n",
    "    index_col=[\"PER_name\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5455/3828268854.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# use pandas dataframe function to write excel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_excel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mr'%s/excel_output.xlsx'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msheet_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'PER'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'xlsxwriter'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/pandas/generic.py\u001B[0m in \u001B[0;36mto_excel\u001B[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001B[0m\n\u001B[1;32m   1151\u001B[0m                 \u001B[0;34m\"Constructor expects DataFrame or Series; however, \"\u001B[0m \u001B[0;34m\"got [%s]\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1152\u001B[0m             )\n\u001B[0;32m-> 1153\u001B[0;31m         return validate_arguments_and_invoke_function(\n\u001B[0m\u001B[1;32m   1154\u001B[0m             \u001B[0mpsdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_to_internal_pandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_excel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1155\u001B[0m         )\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/pandas/utils.py\u001B[0m in \u001B[0;36mvalidate_arguments_and_invoke_function\u001B[0;34m(pobj, pandas_on_spark_func, pandas_func, input_args)\u001B[0m\n\u001B[1;32m    562\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"self\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 564\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mpandas_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    565\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    566\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mto_excel\u001B[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001B[0m\n\u001B[1;32m   2282\u001B[0m             \u001B[0minf_rep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minf_rep\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2283\u001B[0m         )\n\u001B[0;32m-> 2284\u001B[0;31m         formatter.write(\n\u001B[0m\u001B[1;32m   2285\u001B[0m             \u001B[0mexcel_writer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2286\u001B[0m             \u001B[0msheet_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msheet_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pandas/io/formats/excel.py\u001B[0m in \u001B[0;36mwrite\u001B[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001B[0m\n\u001B[1;32m    832\u001B[0m             \u001B[0;31m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    833\u001B[0m             \u001B[0;31m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 834\u001B[0;31m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001B[0m\u001B[1;32m    835\u001B[0m                 \u001B[0mwriter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    836\u001B[0m             )\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pandas/io/excel/_xlsxwriter.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m    182\u001B[0m     ):\n\u001B[1;32m    183\u001B[0m         \u001B[0;31m# Use the xlsxwriter module as the Excel writer.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 184\u001B[0;31m         \u001B[0;32mfrom\u001B[0m \u001B[0mxlsxwriter\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mWorkbook\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    185\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m         \u001B[0mengine_kwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcombine_kwargs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mengine_kwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "source": [
    "# use pandas dataframe function to write excel\n",
    "df.to_excel(r'%s/excel_output.xlsx' % path, sheet_name='PER',engine='xlsxwriter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}