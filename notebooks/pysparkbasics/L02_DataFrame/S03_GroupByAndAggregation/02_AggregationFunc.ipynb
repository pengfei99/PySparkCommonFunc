{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Aggregation functions\n",
    "\n",
    "**Aggregate functions** operate on a group of rows and calculate a single return value for every group.\n",
    "\n",
    "In previous GroupBy section, we have seen some aggregation example. In this section, we will examine all existing aggregation functions in spark. The full list in alphabetic order:\n",
    "\n",
    "- approx_count_distinct, count, countDistinct\n",
    "- avg/mean, max, min, \n",
    "- collect_list, collect_set\n",
    "- grouping : Check if a column is created by aggregation function or not, returns 1 for aggregated, 0 for not aggregated\n",
    "- first,last\n",
    "- sum, sumDistinct\n",
    "- kurtosis, skewness\n",
    "- stddev, stddev_samp, stddev_pop\n",
    "- variance, var_samp, var_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import count, countDistinct, approx_count_distinct, avg, min, max, mean, collect_list, \\\n",
    "    collect_set, grouping, first, last, sum, sumDistinct, skewness, kurtosis, stddev, stddev_samp, stddev_pop, \\\n",
    "    variance, var_samp, var_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local=True\n",
    "\n",
    "if local:\n",
    "    spark=SparkSession.builder.master(\"local[4]\").appName(\"pySparkGroupBy\").getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"SparkArrowCompression\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:master\") \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"8g\") \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------+----------+------+\n",
      "|   name|department|salary|\n",
      "+-------+----------+------+\n",
      "|  Alice|     Sales|  3000|\n",
      "|Michael|     Sales|  4600|\n",
      "| Robert|        IT|  4100|\n",
      "|  Maria|   Finance|  3000|\n",
      "|   Haha|        IT|  3000|\n",
      "|  Scott|   Finance|  3300|\n",
      "|    Jen|   Finance|  3900|\n",
      "|   Jeff| Marketing|  3000|\n",
      "|  Kumar| Marketing|  2000|\n",
      "|   Haha|     Sales|  4100|\n",
      "+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Alice\", \"Sales\", 3000),\n",
    "            (\"Michael\", \"Sales\", 4600),\n",
    "            (\"Robert\", \"IT\", 4100),\n",
    "            (\"Maria\", \"Finance\", 3000),\n",
    "            (\"Haha\", \"IT\", 3000),\n",
    "            (\"Scott\", \"Finance\", 3300),\n",
    "            (\"Jen\", \"Finance\", 3900),\n",
    "            (\"Jeff\", \"Marketing\", 3000),\n",
    "            (\"Kumar\", \"Marketing\", 2000),\n",
    "            (\"Haha\", \"Sales\", 4100)\n",
    "            ]\n",
    "schema = [\"name\", \"department\", \"salary\"]\n",
    "\n",
    "df=spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Count, countDistinct, approx_count_distinct\n",
    "The classic count() will just count row numbers of a group.\n",
    "\n",
    "The **approx_count_distinct** is implemented to avoid count(distinct()) operations. The approx_count_distinct uses an algorithm called **HyperLogLog**. This algorithm can estimate the number of distinct values of greater than 1,000,000,000, where the accuracy of the calculated approximate distinct count value is within 2% of the actual distinct count value. It can do this while using much less memory.\n",
    "\n",
    "Because **count(distinct())** requires more and more memory as the number of distinct values increases. \n",
    "\n",
    "This tutorial shows how the approx_count_distinct function is implemented\n",
    "https://mungingdata.com/apache-spark/hyperloglog-count-distinct/#:~:text=approx_count_distinct%20uses%20the%20HyperLogLog%20algorithm,count()%20will%20run%20slower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(salary)|\n",
      "+-------------+\n",
      "|           10|\n",
      "+-------------+\n",
      "\n",
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|     Sales|    3|\n",
      "|   Finance|    3|\n",
      "| Marketing|    2|\n",
      "|        IT|    2|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregation function can be used after groupBy or on the whole data frame.\n",
    "df.select(count(\"salary\")).show()\n",
    "\n",
    "# below is\n",
    "df.groupBy(\"department\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT salary)|\n",
      "+----------------------+\n",
      "|                     6|\n",
      "+----------------------+\n",
      "\n",
      "+----------------------------------+\n",
      "|count(DISTINCT department, salary)|\n",
      "+----------------------------------+\n",
      "|                                10|\n",
      "+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# countDistinct can take multiple column as argument. If input column number is greater than 1, then\n",
    "# the value combination (col1, col2, ...) must be distinct.\n",
    "\n",
    "# salary distinct value is 6, but (department, salary) distinct value is 10\n",
    "df.select(countDistinct(\"salary\")).show()\n",
    "df.select(countDistinct(\"department\", \"salary\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|approx_count_distinct(salary)|\n",
      "+-----------------------------+\n",
      "|                            6|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# approx count uses less resources\n",
    "df.select(approx_count_distinct(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Get basic stats of a column by using avg/mean, min, max\n",
    "\n",
    "Note mean is the alias of avg. It's not the median function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|avg(salary)|\n",
      "+-----------+\n",
      "|     3400.0|\n",
      "+-----------+\n",
      "\n",
      "+---------+\n",
      "|avg(name)|\n",
      "+---------+\n",
      "|     null|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show avg example\n",
    "# avg can only apply on digit column, if type is mismatch, it returns null\n",
    "df.select(avg(\"salary\")).show()\n",
    "df.select(avg(\"name\")).show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|avg(salary)|\n",
      "+-----------+\n",
      "|     3400.0|\n",
      "+-----------+\n",
      "\n",
      "+---------+\n",
      "|avg(name)|\n",
      "+---------+\n",
      "|     null|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show mean example\n",
    "# mean is the alias of avg. so it works like avg. It's not the median.\n",
    "df.select(mean(\"salary\")).show()\n",
    "df.select(mean(\"name\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(salary)|\n",
      "+-----------+\n",
      "|       2000|\n",
      "+-----------+\n",
      "\n",
      "+---------+\n",
      "|min(name)|\n",
      "+---------+\n",
      "|    Alice|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show min example\n",
    "# min can apply on digit and string column, it uses default sorting order (ascending) to find min\n",
    "df.select(min(\"salary\")).show()\n",
    "df.select(min(\"name\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(salary)|\n",
      "+-----------+\n",
      "|       4600|\n",
      "+-----------+\n",
      "\n",
      "+---------+\n",
      "|max(name)|\n",
      "+---------+\n",
      "|    Scott|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show max example\n",
    "# max can apply on digit and string column, it uses default sorting order (ascending) to find max\n",
    "df.select(max(\"salary\")).show()\n",
    "df.select(max(\"name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 collect_list, collect_set \n",
    "\n",
    "- collect_list() function returns a list that contains all values from an input column with duplicates.\n",
    "- collect_set() function returns a list that contains all values from an input column without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|collect_list(salary)                                        |\n",
      "+------------------------------------------------------------+\n",
      "|[3000, 4600, 4100, 3000, 3000, 3300, 3900, 3000, 2000, 4100]|\n",
      "+------------------------------------------------------------+\n",
      "\n",
      "+----------+----------------------+\n",
      "|department|collect_list(name)    |\n",
      "+----------+----------------------+\n",
      "|Sales     |[Alice, Michael, Haha]|\n",
      "|Finance   |[Maria, Scott, Jen]   |\n",
      "|Marketing |[Jeff, Kumar]         |\n",
      "|IT        |[Robert, Haha]        |\n",
      "+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show collect_list example\n",
    "\n",
    "# collect the salary of employee, note we have duplicates\n",
    "df.select(collect_list(\"salary\")).show(truncate=False)\n",
    "\n",
    "# collect the name of each department\n",
    "# note collect_list can't be used directly after groupBy, it must be in agg()\n",
    "df.groupBy(\"department\").agg(collect_list(\"name\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|collect_set(salary)                 |\n",
      "+------------------------------------+\n",
      "|[4600, 3000, 3900, 4100, 3300, 2000]|\n",
      "+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show collect_set example\n",
    "# note we dont have duplicates\n",
    "df.select(collect_set(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
