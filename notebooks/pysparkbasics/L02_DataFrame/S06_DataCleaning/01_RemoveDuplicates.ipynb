{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Remove duplicate rows\n",
    "\n",
    "To eliminate duplicates rows in data frame, spark provides two methods:\n",
    "\n",
    "- distinct(): Returns a new DataFrame containing the distinct rows in this DataFrame. It takes no arg and return a \n",
    "              new data frame\n",
    "- dropDuplicates(*colName): is used to drop rows based on selected (one or multiple) columns. It takes an array of\n",
    "      column names and return a new data frame.\n",
    "- drop_duplicates(*colName):is a wraper of dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale=True\n",
    "if locale:\n",
    "    spark=SparkSession.builder.master(\"local[4]\").appName(\"RemoveDuplicates\").getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"RemoveDuplicates\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",\"inseefrlab/jupyter-datascience:master\") \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"8g\") \\\n",
    "                      .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1') \\\n",
    "                      .getOrCreate()                   \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1009 18:44:19.898071    1303 request.go:655] Throttling request took 1.034906341s, request: GET:https://kubernetes.default/apis/rbac.authorization.k8s.io/v1?timeout=32s\n",
      "NAME                               READY   STATUS    RESTARTS   AGE\n",
      "flume-test-agent-df8c5b944-vtjbx   1/1     Running   0          20d\n",
      "jupyter-371471-7b5b79fc7f-7k4jj    1/1     Running   0          3d6h\n",
      "kafka-client1                      1/1     Running   0          10d\n",
      "kafka-server-0                     1/1     Running   0          20d\n",
      "kafka-server-1                     1/1     Running   0          20d\n",
      "kafka-server-2                     1/1     Running   0          20d\n",
      "kafka-server-zookeeper-0           1/1     Running   0          20d\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data frame: \n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------+----------+------+\n",
      "|name   |department|salary|\n",
      "+-------+----------+------+\n",
      "|James  |Sales     |3000  |\n",
      "|Michael|Sales     |4600  |\n",
      "|Robert |Sales     |4100  |\n",
      "|Maria  |Finance   |3000  |\n",
      "|James  |Sales     |3000  |\n",
      "|Scott  |Finance   |3300  |\n",
      "|Jen    |Finance   |3900  |\n",
      "|Jeff   |Marketing |3000  |\n",
      "|Kumar  |Marketing |2000  |\n",
      "|Saif   |Sales     |4100  |\n",
      "+-------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(\"James\", \"Sales\", 3000),\n",
    "            (\"Michael\", \"Sales\", 4600),\n",
    "            (\"Robert\", \"Sales\", 4100),\n",
    "            (\"Maria\", \"Finance\", 3000),\n",
    "            (\"James\", \"Sales\", 3000),\n",
    "            (\"Scott\", \"Finance\", 3300),\n",
    "            (\"Jen\", \"Finance\", 3900),\n",
    "            (\"Jeff\", \"Marketing\", 3000),\n",
    "            (\"Kumar\", \"Marketing\", 2000),\n",
    "            (\"Saif\", \"Sales\", 4100)\n",
    "            ]\n",
    "columns = [\"name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "print(\"Source data frame: \")\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.1 Use distinct() to remove duplicates\n",
    "\n",
    "You can notice after we call distinct(), one row James|Sales|3000 has been removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n",
      "|   name|department|salary|\n",
      "+-------+----------+------+\n",
      "|    Jen|   Finance|  3900|\n",
      "|Michael|     Sales|  4600|\n",
      "|  Scott|   Finance|  3300|\n",
      "|  Kumar| Marketing|  2000|\n",
      "|  James|     Sales|  3000|\n",
      "| Robert|     Sales|  4100|\n",
      "|   Jeff| Marketing|  3000|\n",
      "|   Saif|     Sales|  4100|\n",
      "|  Maria|   Finance|  3000|\n",
      "+-------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dedup=df.distinct()\n",
    "df_dedup.show()\n",
    "df_dedup.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to remove duplicates of only several columns, we can call a select() before.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|department|\n",
      "+----------+\n",
      "|     Sales|\n",
      "|   Finance|\n",
      "| Marketing|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dedup_part=df.select(\"department\").distinct()\n",
    "df_dedup_part.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.2 Use dropDuplicates and drop_duplicates to remove duplicates\n",
    "\n",
    "drop_duplicates is just a warper of dropDuplicates. They do exactly the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n",
      "|   name|department|salary|\n",
      "+-------+----------+------+\n",
      "|    Jen|   Finance|  3900|\n",
      "|Michael|     Sales|  4600|\n",
      "|  Scott|   Finance|  3300|\n",
      "|  Kumar| Marketing|  2000|\n",
      "|  James|     Sales|  3000|\n",
      "| Robert|     Sales|  4100|\n",
      "|   Jeff| Marketing|  3000|\n",
      "|   Saif|     Sales|  4100|\n",
      "|  Maria|   Finance|  3000|\n",
      "+-------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop=df.dropDuplicates()\n",
    "df_drop.show()\n",
    "df_drop.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n",
      "|   name|department|salary|\n",
      "+-------+----------+------+\n",
      "|    Jen|   Finance|  3900|\n",
      "|Michael|     Sales|  4600|\n",
      "|  Scott|   Finance|  3300|\n",
      "|  Kumar| Marketing|  2000|\n",
      "|  James|     Sales|  3000|\n",
      "| Robert|     Sales|  4100|\n",
      "|   Jeff| Marketing|  3000|\n",
      "|   Saif|     Sales|  4100|\n",
      "|  Maria|   Finance|  3000|\n",
      "+-------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop=df.drop_duplicates()\n",
    "df_drop.show()\n",
    "df_drop.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give a list of column names as arguments to remove duplicates of certain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n",
      "|   name|department|salary|\n",
      "+-------+----------+------+\n",
      "|Michael|     Sales|  4600|\n",
      "| Robert|     Sales|  4100|\n",
      "|    Jen|   Finance|  3900|\n",
      "|  Maria|   Finance|  3000|\n",
      "|  Scott|   Finance|  3300|\n",
      "|  Kumar| Marketing|  2000|\n",
      "|  James|     Sales|  3000|\n",
      "|   Jeff| Marketing|  3000|\n",
      "+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop1=df.drop_duplicates([\"department\",\"salary\"])\n",
    "df_drop1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "| name|department|salary|\n",
      "+-----+----------+------+\n",
      "|James|     Sales|  3000|\n",
      "|Maria|   Finance|  3000|\n",
      "| Jeff| Marketing|  3000|\n",
      "+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop2=df.drop_duplicates([\"department\"])\n",
    "df_drop2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to distinct(), drop_duplicates can keep all columns when removing duplicates based on certain columns. It's more interesting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
