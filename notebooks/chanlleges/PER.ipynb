{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Find the best PER contract\n",
    "\n",
    "PER (Plan d’Epargne Retraite) is a French investment account which allows you to prepare your retirement and reduce some tax. But there are so many banks and insurance company that offers various contract of PER.\n",
    "\n",
    "The objective of this challenge is to find the `best PER contract of 2022` in the market.\n",
    "\n",
    "The raw data is coming from https://www.francetransactions.com/per-plan-epargne-retraite-206/comparatif-per.html\n",
    "\n",
    "\n",
    "## Data description\n",
    "\n",
    "\n",
    "- Frais de gestion sur les unités de compte pour les supports en assurance-vie. Frais de gestion des produits sur les encours du contrat pour les autres supports (compte-titres, etc.).\n",
    "\n",
    "- Taux publié par les assureurs, nets des frais de gestion, nets de prélèvements sociaux.\n",
    "\n",
    "- Taux nets pour les épargnants, nets des prélèvements sociaux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as ps\n",
    "from pyspark.sql.functions import col, desc\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/10 20:21:46 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.184.146 instead (on interface ens33)\n",
      "22/08/10 20:21:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/08/10 20:21:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "local=True\n",
    "if local:\n",
    "    spark=SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"PER_challenge\")\\\n",
    "                  .getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"PER_challenge\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",os.environ['IMAGE_NAME']) \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"8g\") \\\n",
    "                      .config('spark.jars.packages','com.crealytics:spark-excel_2.12:3.1.2_0.17.1') \\\n",
    "                      .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "file_path=\"../../data/per.xls\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    }
   ],
   "source": [
    "pdf=ps.read_excel(file_path, sheet_name='per', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Assureur/Support  Avis sur 5  \\\nPER                                                                            \nABEILLE RETRAITE PLURIELLE      ABEILLE RETRAITE PROFESSIONNELLE         NaN   \nAFER RETRAITE INDIVIDUELLE                               ABEILLE         NaN   \nALLIANZ PER HORIZON                                      ALLIANZ         NaN   \nAMBITION RETRAITE INDIVIDUELLE                       LA MONDIALE         NaN   \nAMPLI-PER LIBERTE                                 AMPLI-MUTUELLE         NaN   \n\n                                Frais Vers.  Frais Gestion Fonds ?  \\\nPER                                                                  \nABEILLE RETRAITE PLURIELLE              5.0                   1.00   \nAFER RETRAITE INDIVIDUELLE              3.0                   1.00   \nALLIANZ PER HORIZON                     4.8                   0.85   \nAMBITION RETRAITE INDIVIDUELLE          3.9                   0.70   \nAMPLI-PER LIBERTE                       0.0                   0.50   \n\n                                Frais Gestion UC  Frais/rente  \\\nPER                                                             \nABEILLE RETRAITE PLURIELLE                  1.00          NaN   \nAFER RETRAITE INDIVIDUELLE                  1.00          0.0   \nALLIANZ PER HORIZON                         0.85          NaN   \nAMBITION RETRAITE INDIVIDUELLE              0.70          0.0   \nAMPLI-PER LIBERTE                           0.40          0.0   \n\n                                                 Fonds euros  Taux brut  \\\nPER                                                                       \nABEILLE RETRAITE PLURIELLE                 ABEILLE EURO PERP        NaN   \nAFER RETRAITE INDIVIDUELLE      ABEILLE RP SECURITE RETRAITE        NaN   \nALLIANZ PER HORIZON                         ALLIANZ RETRAITE        NaN   \nAMBITION RETRAITE INDIVIDUELLE          FONDS EUROS RETRAITE        NaN   \nAMPLI-PER LIBERTE                            AMPLI PER EUROS        NaN   \n\n                                Nombre SCPI  Nombre SCI  Nombre OPCI  \\\nPER                                                                    \nABEILLE RETRAITE PLURIELLE                0           0            0   \nAFER RETRAITE INDIVIDUELLE                0           0            0   \nALLIANZ PER HORIZON                       0           0            0   \nAMBITION RETRAITE INDIVIDUELLE            0           0            0   \nAMPLI-PER LIBERTE                         2           0            0   \n\n                                Nombre ETF  Nombre UC  \nPER                                                    \nABEILLE RETRAITE PLURIELLE               0         80  \nAFER RETRAITE INDIVIDUELLE               0         80  \nALLIANZ PER HORIZON                      0         92  \nAMBITION RETRAITE INDIVIDUELLE           0          0  \nAMPLI-PER LIBERTE                        3          4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Assureur/Support</th>\n      <th>Avis sur 5</th>\n      <th>Frais Vers.</th>\n      <th>Frais Gestion Fonds ?</th>\n      <th>Frais Gestion UC</th>\n      <th>Frais/rente</th>\n      <th>Fonds euros</th>\n      <th>Taux brut</th>\n      <th>Nombre SCPI</th>\n      <th>Nombre SCI</th>\n      <th>Nombre OPCI</th>\n      <th>Nombre ETF</th>\n      <th>Nombre UC</th>\n    </tr>\n    <tr>\n      <th>PER</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ABEILLE RETRAITE PLURIELLE</th>\n      <td>ABEILLE RETRAITE PROFESSIONNELLE</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>NaN</td>\n      <td>ABEILLE EURO PERP</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>AFER RETRAITE INDIVIDUELLE</th>\n      <td>ABEILLE</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>ABEILLE RP SECURITE RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>ALLIANZ PER HORIZON</th>\n      <td>ALLIANZ</td>\n      <td>NaN</td>\n      <td>4.8</td>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>NaN</td>\n      <td>ALLIANZ RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>AMBITION RETRAITE INDIVIDUELLE</th>\n      <td>LA MONDIALE</td>\n      <td>NaN</td>\n      <td>3.9</td>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>0.0</td>\n      <td>FONDS EUROS RETRAITE</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>AMPLI-PER LIBERTE</th>\n      <td>AMPLI-MUTUELLE</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>AMPLI PER EUROS</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 55 entries, ABEILLE RETRAITE PLURIELLE to YOMONI RETRAITE\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Assureur/Support       55 non-null     object \n",
      " 1   Avis sur 5             0 non-null      float64\n",
      " 2   Frais Vers.            55 non-null     float64\n",
      " 3   Frais Gestion Fonds ?  55 non-null     float64\n",
      " 4   Frais Gestion UC       55 non-null     float64\n",
      " 5   Frais/rente            27 non-null     float64\n",
      " 6   Fonds euros            47 non-null     object \n",
      " 7   Taux brut              0 non-null      float64\n",
      " 8   Nombre SCPI            55 non-null     int64  \n",
      " 9   Nombre SCI             55 non-null     int64  \n",
      " 10  Nombre OPCI            55 non-null     int64  \n",
      " 11  Nombre ETF             55 non-null     int64  \n",
      " 12  Nombre UC              55 non-null     int64  \n",
      "dtypes: float64(6), int64(5), object(2)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "pdf.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert pandas dataframe to spark dataframe\n",
    "\n",
    "While converting the Pandas DataFrame to Spark DataFrame, it may throw error as Spark is not able to infer correct data type for the columns due to mix type of data in columns.\n",
    "\n",
    "Pandas create mix type because of the data have missing values which pushes Pandas to represent them as mixed types (e.g. string for not missing, NaN for missing values).\n",
    "\n",
    "In this case you just need to explicitly tell Spark to use a correct datatype by creating a new schema and using it in createDataFrame() definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "field Fonds euros: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.DoubleType'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5361/3533362542.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreateDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/session.py\u001B[0m in \u001B[0;36mcreateDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    671\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhas_pandas\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpandas\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    672\u001B[0m             \u001B[0;31m# Create a DataFrame from pandas DataFrame.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 673\u001B[0;31m             return super(SparkSession, self).createDataFrame(\n\u001B[0m\u001B[1;32m    674\u001B[0m                 data, schema, samplingRatio, verifySchema)\n\u001B[1;32m    675\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py\u001B[0m in \u001B[0;36mcreateDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    338\u001B[0m                     \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    339\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_convert_from_pandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimezone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 340\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    341\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    342\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_convert_from_pandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimezone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_create_dataframe\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    698\u001B[0m             \u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_createFromRDD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    699\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 700\u001B[0;31m             \u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_createFromLocal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    701\u001B[0m         \u001B[0mjrdd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSerDeUtil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoJavaArray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrdd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_to_java_object_rdd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    702\u001B[0m         \u001B[0mjdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapplySchemaToPythonRDD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjrdd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrdd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_createFromLocal\u001B[0;34m(self, data, schema)\u001B[0m\n\u001B[1;32m    510\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    511\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 512\u001B[0;31m             \u001B[0mstruct\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_inferSchemaFromList\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    513\u001B[0m             \u001B[0mconverter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_create_converter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstruct\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    514\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_inferSchemaFromList\u001B[0;34m(self, data, names)\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"can not infer schema from empty dataset\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 439\u001B[0;31m         \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_merge_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0m_infer_schema\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mrow\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    440\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_has_nulltype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Some of types cannot be determined after inferring\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/types.py\u001B[0m in \u001B[0;36m_merge_type\u001B[0;34m(a, b, name)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mStructType\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1108\u001B[0m         \u001B[0mnfs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataType\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfields\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1109\u001B[0;31m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001B[0m\u001B[1;32m   1110\u001B[0m                                                   name=new_name(f.name)))\n\u001B[1;32m   1111\u001B[0m                   for f in a.fields]\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/types.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mStructType\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1108\u001B[0m         \u001B[0mnfs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataType\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfields\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1109\u001B[0;31m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001B[0m\u001B[1;32m   1110\u001B[0m                                                   name=new_name(f.name)))\n\u001B[1;32m   1111\u001B[0m                   for f in a.fields]\n",
      "\u001B[0;32m~/.cache/pypoetry/virtualenvs/sparkcommonfunc-3iAQ1Rpl-py3.8/lib/python3.8/site-packages/pyspark/sql/types.py\u001B[0m in \u001B[0;36m_merge_type\u001B[0;34m(a, b, name)\u001B[0m\n\u001B[1;32m   1102\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# TODO: type cast (such as int -> long)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1104\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_msg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Can not merge type %s and %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1106\u001B[0m     \u001B[0;31m# same type\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: field Fonds euros: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.DoubleType'>"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pdf)\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a set of functions that will convert pandas dataframe to spark dataframe correctly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Build spark column type\n",
    "def build_type(f):\n",
    "    if f == 'datetime64[ns]': return TimestampType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return DoubleType()\n",
    "    elif f == 'float32': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "# build spark column name, need to be changed for each dataset\n",
    "def build_col_name(col_name:str)->str:\n",
    "    # remove space, ., ?\n",
    "    col_name=col_name.strip(\"?\").strip(\".\").strip()\n",
    "    # replace / by _\n",
    "    col_name=col_name.replace(\"/\",\"_\")\n",
    "    # replace space by _\n",
    "    col_name=col_name.replace(\" \",\"_\")\n",
    "    return col_name\n",
    "\n",
    "def build_struct_field(col_name:str, pandas_col_type):\n",
    "    try: spark_col_type = build_type(pandas_col_type)\n",
    "    except: spark_col_type = StringType()\n",
    "    col_name=build_col_name(col_name)\n",
    "    return StructField(col_name, spark_col_type,nullable=True)\n",
    "\n",
    "# Given pandas dataframe, it will return a spark's dataframe.\n",
    "def pandas_to_spark(pandas_df):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for col_name, col_type in zip(columns, types):\n",
    "        struct_list.append(build_struct_field(col_name, col_type))\n",
    "    spark_schema = StructType(struct_list)\n",
    "    return spark.createDataFrame(pandas_df, spark_schema)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df=pandas_to_spark(pdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+-------------------+----------------+-----------+--------------------+---------+-----------+----------+-----------+----------+---------+\n",
      "|    Assureur_Support|Avis_sur_5|Frais_Vers|Frais_Gestion_Fonds|Frais_Gestion_UC|Frais_rente|         Fonds_euros|Taux_brut|Nombre_SCPI|Nombre_SCI|Nombre_OPCI|Nombre_ETF|Nombre_UC|\n",
      "+--------------------+----------+----------+-------------------+----------------+-----------+--------------------+---------+-----------+----------+-----------+----------+---------+\n",
      "|ABEILLE RETRAITE ...|       NaN|       5.0|                1.0|             1.0|        NaN|   ABEILLE EURO PERP|      NaN|          0|         0|          0|         0|       80|\n",
      "|             ABEILLE|       NaN|       3.0|                1.0|             1.0|        0.0|ABEILLE RP SECURI...|      NaN|          0|         0|          0|         0|       80|\n",
      "|             ALLIANZ|       NaN|       4.8|               0.85|            0.85|        NaN|    ALLIANZ RETRAITE|      NaN|          0|         0|          0|         0|       92|\n",
      "|         LA MONDIALE|       NaN|       3.9|                0.7|             0.7|        0.0|FONDS EUROS RETRAITE|      NaN|          0|         0|          0|         0|        0|\n",
      "|      AMPLI-MUTUELLE|       NaN|       0.0|                0.5|             0.4|        0.0|     AMPLI PER EUROS|      NaN|          2|         0|          0|         3|        4|\n",
      "|            ANTARIUS|       NaN|       3.9|               0.84|            0.84|        0.8|                 NaN|      NaN|          0|         0|          0|         0|       36|\n",
      "|                 AXA|       NaN|       5.0|               0.75|             1.0|        NaN|      AGIPI EURO FAR|      NaN|          0|         0|          0|         0|       60|\n",
      "|CARDIF ASSURANCE VIE|       NaN|       2.5|                0.7|             0.7|        0.0|FONDS EUROS CARDI...|      NaN|          0|         0|          1|         0|       26|\n",
      "|          PREPAR VIE|       NaN|       4.8|               0.85|            0.85|        NaN|                 NaN|      NaN|          0|         0|          0|         0|        9|\n",
      "|      CNP ASSURANCES|       NaN|       2.0|               0.85|            0.85|        0.8|   CNP CACHEMIRE PER|      NaN|          0|         0|          0|         0|       75|\n",
      "|              APICIL|       NaN|       0.0|               0.85|             0.6|        NaN| APICIL EURO GARANTI|      NaN|         17|         4|          5|         0|      600|\n",
      "|     LE CONSERVATEUR|       NaN|       4.5|               0.96|            0.96|        NaN|     LE CONSERVATEUR|      NaN|          0|         0|          1|         0|       71|\n",
      "|             PREDICA|       NaN|       2.5|                0.8|            0.96|        NaN| PER CREDIT AGRICOLE|      NaN|          0|         0|          0|         0|      107|\n",
      "|     CREDIT AGRICOLE|       NaN|       0.0|                0.0|             0.4|        0.8|                 NaN|      NaN|          0|         0|          0|         0|        0|\n",
      "|             ABEILLE|       NaN|       0.0|                0.6|             0.6|        0.0|ABEILLE RP GARANT...|      NaN|          0|         0|          1|         0|      110|\n",
      "|             GARANCE|       NaN|       3.0|                0.9|             0.9|        0.0|                 NaN|      NaN|          0|         0|          0|         0|        0|\n",
      "|        GROUPAMA VIE|       NaN|       4.5|                0.7|            0.96|        NaN|    GROUPAMA GAN VIE|      NaN|          0|         0|          1|         0|       35|\n",
      "|             SPIRICA|       NaN|       2.5|                2.0|             1.0|        2.0|EURO NOUVELLE GEN...|      NaN|          0|         0|          0|         0|      130|\n",
      "|        GENERALI VIE|       NaN|      4.95|                0.7|            0.96|        2.0|     PERP Anthologie|      NaN|          0|         0|          0|         0|       15|\n",
      "|CREDIT AGRICOLE A...|       NaN|       2.5|                0.8|            0.95|        NaN| PER CREDIT AGRICOLE|      NaN|          0|         0|          0|         0|      140|\n",
      "+--------------------+----------+----------+-------------------+----------------+-----------+--------------------+---------+-----------+----------+-----------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Assureur_Support: string (nullable = true)\n",
      " |-- Avis_sur_5: double (nullable = true)\n",
      " |-- Frais_Vers: double (nullable = true)\n",
      " |-- Frais_Gestion_Fonds: double (nullable = true)\n",
      " |-- Frais_Gestion_UC: double (nullable = true)\n",
      " |-- Frais_rente: double (nullable = true)\n",
      " |-- Fonds_euros: string (nullable = true)\n",
      " |-- Taux_brut: double (nullable = true)\n",
      " |-- Nombre_SCPI: long (nullable = true)\n",
      " |-- Nombre_SCI: long (nullable = true)\n",
      " |-- Nombre_OPCI: long (nullable = true)\n",
      " |-- Nombre_ETF: long (nullable = true)\n",
      " |-- Nombre_UC: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Assureur_Support', 'Avis_sur_5', 'Frais_Vers', 'Frais_Gestion_Fonds', 'Frais_Gestion_UC', 'Frais_rente', 'Fonds_euros', 'Taux_brut', 'Nombre_SCPI', 'Nombre_SCI', 'Nombre_OPCI', 'Nombre_ETF', 'Nombre_UC']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# column definition\n",
    "After the cleaning, we have the following column\n",
    "\n",
    "- Assureur_Support: Name of the organization of the contract\n",
    "- Avis_sur_5: point given by user (1 to 5)\n",
    "- Frais_Vers: Frais sur versements maximum : Des réductions importantes, jusqu'à l'annulation complète des frais sur versements (0%), peuvent être proposées aux épargnants, selon leur intermédiaire. (This tells you how much money you need to pay when you transfer money into your PER account, for example if it's 5%, and you put 100 euros into your account, you only invest 95 euros. With a 2% gain per year, it will take long time to just gain back your capital. **So, I highly recommend you to avoid all contracts that has more than 2% frais versement** vous conseillons donc d’éviter les contrats qui prévoient des frais de versement supérieurs à 2%.)\n",
    "- Frais_Gestion_Fonds: Frais de gestion sur le fonds euros pour les supports assurance-vie. You need to pay every year of your investment,\n",
    "     For example, if it's 1% and you have 100 euros in your PER account, you will lose 1 euros each year.\n",
    "- Frais_Gestion_UC: Frais de gestion de compte pour les autres supports (compte-titres, etc.). Same thing as above\n",
    "- Frais_rente: You need to pay when you start your retirement, the insurance company will pay you each month a little. For example, if they pay you 100 euros each month, and the frais_rente is 3%, then you will only receive 97 euros.\n",
    "- Fonds_euros: The fonds which the company will use to invest your money.\n",
    "- Taux_brut: The gain of the investment of your capitale. Brut means you need to remove the frais gestion to get the real gain.\n",
    "- Nombre_SCPI: Société Civile de Placement Immobilier est simple(il s'agit d'une structure qui vous permet d'investir dans des biens immobiliers). The number of different SCPI that the contract allows you to choose\n",
    "- Nombre_SCI: Société civile immobilière. Idem to above\n",
    "- Nombre_OPCI: Organisme de Placement Collectif Immobilier\n",
    "- Nombre_ETF:  exchange-traded fund\n",
    "- Nombre_UC:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So our objective is to find a low frais, high taux PER contract\n",
    "\n",
    "First let's get some baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "target_col=[\"Assureur_Support\",\"Frais_Vers\",\"Frais_Gestion_Fonds\",\"Frais_Gestion_UC\",\"Frais_rente\",\"Taux_brut\"]\n",
    "\n",
    "feature_col=[\"Frais_Vers\",\"Frais_Gestion_Fonds\",\"Frais_Gestion_UC\",\"Frais_rente\",\"Taux_brut\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+-------------------+-----------+---------+\n",
      "|summary|       Frais_Vers|Frais_Gestion_Fonds|   Frais_Gestion_UC|Frais_rente|Taux_brut|\n",
      "+-------+-----------------+-------------------+-------------------+-----------+---------+\n",
      "|  count|               55|                 55|                 55|         55|       55|\n",
      "|   mean|2.067272727272727| 0.8170909090909091| 0.7503636363636363|        NaN|      NaN|\n",
      "| stddev|1.932955379287504| 0.3530642199860295|0.24142297012722402|        NaN|      NaN|\n",
      "|    min|              0.0|                0.0|                0.0|        0.0|      NaN|\n",
      "|    25%|              0.0|               0.65|                0.6|        0.8|      NaN|\n",
      "|    50%|              2.5|                0.8|               0.84|        NaN|      NaN|\n",
      "|    75%|              3.9|                0.9|               0.96|        2.0|      NaN|\n",
      "|    max|              5.0|                2.0|                1.2|        NaN|      NaN|\n",
      "+-------+-----------------+-------------------+-------------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_target_col=df.select(target_col)\n",
    "df_target_col.select(feature_col).summary().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+----------------+-----------+---------+\n",
      "|    Assureur_Support|Frais_Vers|Frais_Gestion_Fonds|Frais_Gestion_UC|Frais_rente|Taux_brut|\n",
      "+--------------------+----------+-------------------+----------------+-----------+---------+\n",
      "|     CREDIT AGRICOLE|       0.0|                0.0|             0.3|        0.8|      NaN|\n",
      "|     CREDIT AGRICOLE|       0.0|                0.0|             0.4|        0.8|      NaN|\n",
      "|          ORADEA VIE|       0.0|                0.5|            0.22|        0.0|      NaN|\n",
      "|      AMPLI-MUTUELLE|       0.0|                0.5|             0.4|        0.0|      NaN|\n",
      "|             ABEILLE|       0.0|                0.6|             0.6|        0.0|      NaN|\n",
      "|                 MIF|       0.0|                0.6|             0.6|        0.6|      NaN|\n",
      "|SWISSLIFE ASSURAN...|       0.0|                0.6|             0.6|        NaN|      NaN|\n",
      "|           SWISSLIFE|       0.0|               0.65|            0.84|        NaN|      NaN|\n",
      "|           SURAVENIR|       0.0|                0.8|             0.6|        0.8|      NaN|\n",
      "|              APICIL|       0.0|               0.85|             0.6|       0.75|      NaN|\n",
      "|              APICIL|       0.0|               0.85|             0.6|        NaN|      NaN|\n",
      "|              APICIL|       0.0|               0.85|             0.6|        NaN|      NaN|\n",
      "|              APICIL|       0.0|               0.85|             0.6|        NaN|      NaN|\n",
      "|              APICIL|       0.0|               0.85|             0.6|        NaN|      NaN|\n",
      "|              APICIL|       0.0|               0.85|             0.6|        NaN|      NaN|\n",
      "|               CARAC|       0.0|                0.9|             0.9|        2.0|      NaN|\n",
      "|            GENERALI|       0.0|                0.9|             1.0|        NaN|      NaN|\n",
      "|          SWISS LIFE|       0.0|                1.0|             1.0|        0.0|      NaN|\n",
      "|           SURAVENIR|       0.0|                1.0|             1.0|        1.0|      NaN|\n",
      "|              APICIL|       0.0|                1.0|             1.0|        NaN|      NaN|\n",
      "+--------------------+----------+-------------------+----------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.orderBy(col(\"Frais_Vers\"),col(\"Frais_Gestion_Fonds\"),col(\"Frais_Gestion_UC\"),col(\"Frais_rente\"),col(\"Taux_brut\").desc()).select(target_col).show(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}