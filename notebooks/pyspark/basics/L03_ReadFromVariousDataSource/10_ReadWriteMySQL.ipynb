{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-11T08:01:20.657195677Z",
     "start_time": "2023-09-11T08:01:20.032944261Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create spark session\n",
    "\n",
    "As spark use jdbc to connect to the mysql server. We need to add the dependencies jar into the spark context\n",
    "\n",
    "You can notice the below line in the code\n",
    "\n",
    "```text\n",
    "# add local jar file\n",
    "config(\"spark.jars\",\"/home/pengfei/git/RecetteConstance/app/lib/mysql-connector-java-8.0.30.jar\")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eeecfbca3d7cde6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/11 10:01:31 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "23/09/11 10:01:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/09/11 10:01:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "local=True\n",
    "if local:\n",
    "    spark=(SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"sparkMysql\")\\\n",
    "                  .config(\"spark.jars\",\"/home/pengfei/git/RecetteConstance/app/lib/mysql-connector-java-8.0.30.jar\") \\\n",
    "                   .getOrCreate())\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"RepartitionCSV\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",os.environ[\"IMAGE_NAME\"]) \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"8g\") \\\n",
    "                      .config(\"spark.kubernetes.driver.pod.name\", os.environ[\"POD_NAME\"]) \\\n",
    "                      .config('spark.jars.packages','org.postgresql:postgresql:42.2.24') \\\n",
    "                      .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T08:01:36.616051195Z",
     "start_time": "2023-09-11T08:01:25.393459265Z"
    }
   },
   "id": "24cb2514fe29403a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "columns = [\"id\", \"name\",\"age\",\"gender\"]\n",
    "data = [(1, \"James\",30,\"M\"), (2, \"Ann\",40,\"F\"),\n",
    "    (3, \"Jeff\",41,\"M\"),(4, \"Jennifer\",20,\"F\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T08:01:41.502591589Z",
     "start_time": "2023-09-11T08:01:41.480483500Z"
    }
   },
   "id": "5c7bcb4fa89ff880"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+\n",
      "| id|    name|age|gender|\n",
      "+---+--------+---+------+\n",
      "|  1|   James| 30|     M|\n",
      "|  2|     Ann| 40|     F|\n",
      "|  3|    Jeff| 41|     M|\n",
      "|  4|Jennifer| 20|     F|\n",
      "+---+--------+---+------+\n"
     ]
    }
   ],
   "source": [
    "sampleDF = spark.createDataFrame(data,schema=columns)\n",
    "sampleDF.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T08:01:58.986980095Z",
     "start_time": "2023-09-11T08:01:48.506102315Z"
    }
   },
   "id": "4f865af2a9fd69d5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "sampleDF.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T08:02:02.419108453Z",
     "start_time": "2023-09-11T08:02:02.398058942Z"
    }
   },
   "id": "4367346ae8558421"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write dataframe to mysql server\n",
    "\n",
    "To write a dataframe to the mysql server, we need four basic required information:\n",
    "- **database name** : which database we will write to \n",
    "- **table name**: The table name which will host the data\n",
    "- **uid of the connexion credential**: user id to connect to the database\n",
    "- **password of the connexion credential**: user password to connect to the database\n",
    "\n",
    "The parallelism(jdbc connection number) of write depends on the partition number of the dataframe. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79511e4a9b382daa"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# mysql connexion config\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "dbName=\"constance\"\n",
    "mysqlUrl = f\"jdbc:mysql://{host}:{port}/{dbName}\"\n",
    "driverName = \"com.mysql.cj.jdbc.Driver\"\n",
    "tabName = \"employee\"\n",
    "uid=\"recette\"\n",
    "pwd = \"casd2023\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T14:03:11.420399256Z",
     "start_time": "2023-09-11T14:03:11.401771921Z"
    }
   },
   "id": "5496286b403891c4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view 'employee' already exists. SaveMode: ErrorIfExists.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msampleDF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mjdbc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdriver\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcom.mysql.cj.jdbc.Driver\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43murl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mjdbc:mysql://localhost:3306/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdbName\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdbtable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtabName\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43muid\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpassword\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mpwd\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/recetteconstance-srJ77eiC-py3.8/lib/python3.8/site-packages/pyspark/sql/readwriter.py:966\u001B[0m, in \u001B[0;36mDataFrameWriter.save\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n\u001B[1;32m    964\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mformat\u001B[39m)\n\u001B[1;32m    965\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 966\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    967\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jwrite\u001B[38;5;241m.\u001B[39msave(path)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/recetteconstance-srJ77eiC-py3.8/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/recetteconstance-srJ77eiC-py3.8/lib/python3.8/site-packages/pyspark/sql/utils.py:196\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    192\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: Table or view 'employee' already exists. SaveMode: ErrorIfExists."
     ]
    }
   ],
   "source": [
    "sampleDF.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"driver\",driverName) \\\n",
    "  .option(\"url\", mysqlUrl) \\\n",
    "  .option(\"dbtable\", f\"{tabName}\") \\\n",
    "  .option(\"user\", f\"{uid}\") \\\n",
    "  .option(\"password\", f\"{pwd}\") \\\n",
    "  .save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T13:27:45.376173130Z",
     "start_time": "2023-09-11T13:27:43.386714930Z"
    }
   },
   "id": "91bac7bc65c6fece"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some Useful options \n",
    "\n",
    "- **mode(\"overwrite\")**: It drops the table if already exists by default and re-creates a new one without indexes.\n",
    "- **mode(\"append\")**: It conserves the old rows in the table, and append the new rows to the existing MySQL database table.\n",
    "- **option(\"truncate\",\"true\")**:  It retains the index.\n",
    "- **option(\"mssqlIsolationLevel\", \"READ_UNCOMMITTED\")** : This connector by default uses READ_COMMITTED isolation level. You can change the default value by using this option."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1f465ea5b28120a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read the mysql server table into a dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff0223c60d779ef6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "readDF= spark.read \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "  .option(\"url\", f\"jdbc:mysql://localhost:3306/{dbName}\") \\\n",
    "  .option(\"dbtable\", f\"{tabName}\") \\\n",
    "  .option(\"user\", f\"{uid}\") \\\n",
    "  .option(\"password\", f\"{pwd}\") \\\n",
    "  .load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:14:00.510797611Z",
     "start_time": "2023-09-08T14:14:00.391301185Z"
    }
   },
   "id": "1979ce54cf33d099"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+\n",
      "| id|    name|age|gender|\n",
      "+---+--------+---+------+\n",
      "|  4|Jennifer| 20|     F|\n",
      "|  3|    Jeff| 41|     M|\n",
      "|  2|     Ann| 40|     F|\n",
      "|  1|   James| 30|     M|\n",
      "+---+--------+---+------+\n"
     ]
    }
   ],
   "source": [
    "readDF.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:14:13.722613681Z",
     "start_time": "2023-09-08T14:14:13.439398787Z"
    }
   },
   "id": "2087e5b271a47c0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read data with projection/predicate pushdown\n",
    "\n",
    "We can use specific columns and condition to load less data into spark, so it can be more performed.\n",
    "\n",
    "Some important points:\n",
    "- **Note that you can use either `dbtable` or `query` option, but not both at a time** \n",
    "- When use `query` option, the query must start with `select` can't be simple table name.\n",
    "- **When using the `dbtable` option, you canâ€™t use `partitionColumn` option.**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8057b94dec0edad6"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "query = \"select id, gender from employee where age>23\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:24:11.718928851Z",
     "start_time": "2023-09-08T14:24:11.664350567Z"
    }
   },
   "id": "be648ed5689f1857"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "pushDownDF= spark.read \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "  .option(\"url\", f\"jdbc:mysql://localhost:3306/{dbName}\") \\\n",
    "  .option(\"query\", f\"{query}\") \\\n",
    "  .option(\"user\", f\"{uid}\") \\\n",
    "  .option(\"password\", f\"{pwd}\") \\\n",
    "  .load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:24:12.367673619Z",
     "start_time": "2023-09-08T14:24:12.331488365Z"
    }
   },
   "id": "fc3cd42fc6dbe619"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|gender|\n",
      "+---+------+\n",
      "|  3|     M|\n",
      "|  2|     F|\n",
      "|  1|     M|\n",
      "+---+------+\n"
     ]
    }
   ],
   "source": [
    "pushDownDF.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:24:30.179958805Z",
     "start_time": "2023-09-08T14:24:30.046471263Z"
    }
   },
   "id": "14e7fb6eff7a1f40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read mysql table in parallel\n",
    "\n",
    "Two useful options if you want to read the table in parallel:\n",
    "\n",
    "- Use option **numPartitions** to read MySQL table in parallel. This property also determines the maximum number of concurrent JDBC connections to use. \n",
    "- Use option **fetchsize** to specify how many rows to fetch at a time, by default it is set to 10.\n",
    "\n",
    "The below example creates the DataFrame with 2 partitions (2 jdbc connection in parallel), and fetch 20 row at a time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da1f1d68222953b2"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "query2=\"select * from employee\"\n",
    "paraReadDF = spark.read \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "  .option(\"url\", f\"jdbc:mysql://localhost:3306/{dbName}\") \\\n",
    "  .option(\"query\", f\"{query2}\").option(\"numPartitions\",\"2\").option(\"fetchsize\",\"20\").option(\"user\", f\"{uid}\")\\\n",
    "  .option(\"password\", f\"{pwd}\")\\\n",
    "  .load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:41:06.221182037Z",
     "start_time": "2023-09-08T14:41:06.178149515Z"
    }
   },
   "id": "c716fe79d48562e6"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+\n",
      "| id|    name|age|gender|\n",
      "+---+--------+---+------+\n",
      "|  4|Jennifer| 20|     F|\n",
      "|  3|    Jeff| 41|     M|\n",
      "|  2|     Ann| 40|     F|\n",
      "|  1|   James| 30|     M|\n",
      "+---+--------+---+------+\n"
     ]
    }
   ],
   "source": [
    "paraReadDF.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:41:08.841633062Z",
     "start_time": "2023-09-08T14:41:08.718666441Z"
    }
   },
   "id": "8d10ea3697522bc8"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraReadDF.rdd.getNumPartitions()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:40:44.148485171Z",
     "start_time": "2023-09-08T14:40:44.014302267Z"
    }
   },
   "id": "e16fce0c08428618"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The partition number is 1, so the parallel read failed. Let's try with a bigger file\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ce4f6089428909c"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sfPath=\"/home/pengfei/data_set/sf_fire/sf_fire_snappy.parquet\"\n",
    "df = spark.read.parquet(sfPath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:44:17.039149111Z",
     "start_time": "2023-09-08T14:44:15.356711074Z"
    }
   },
   "id": "29a218f9c39e6a78"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/08 16:44:23 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+-----------+----+----------------+--------+-------------+-------+--------------------+--------------+--------------+--------------------------+----------------------+------------------+--------------------+----------------+--------------------+\n",
      "|CallNumber|UnitID|IncidentNumber|            CallType|  CallDate| WatchDate|        ReceivedDtTm|           EntryDtTm|        DispatchDtTm|        ResponseDtTm|         OnSceneDtTm|       TransportDtTm|        HospitalDtTm|CallFinalDisposition|       AvailableDtTm|             Address|         City|ZipcodeofIncident|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|       CallTypeGroup|NumberofAlarms|      UnitType|Unitsequenceincalldispatch|FirePreventionDistrict|SupervisorDistrict|NeighborhoodDistrict|        Location|               RowID|\n",
      "+----------+------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+-----------+----+----------------+--------+-------------+-------+--------------------+--------------+--------------+--------------------------+----------------------+------------------+--------------------+----------------+--------------------+\n",
      "| 210391607|   E19|      21017645|              Alarms|02/08/2021|02/08/2021|02/08/2021 01:00:...|02/08/2021 01:01:...|02/08/2021 01:01:...|02/08/2021 01:03:...|02/08/2021 01:05:...|                null|                null|                Fire|02/08/2021 01:18:...|400 Block of SERR...|San Francisco|            94132|      B08|         19|8581|               3|       3|            3|   true|               Alarm|             1|        ENGINE|                         1|                     8|                 7|           Lakeshore|   210391607-E19|POINT (-122.48045...|\n",
      "| 210391164|   T04|      21017596|              Alarms|02/08/2021|02/08/2021|02/08/2021 10:54:...|02/08/2021 10:56:...|02/08/2021 10:56:...|02/08/2021 10:57:...|02/08/2021 10:59:...|                null|                null|                Fire|02/08/2021 11:06:...|600 Block of LONG...|San Francisco|            94158|      B03|         04|2264|               3|       3|            3|  false|               Alarm|             1|         TRUCK|                         1|                     3|                 6|         Mission Bay|   210391164-T04|POINT (-122.39227...|\n",
      "| 210391034|   E16|      21017578|Citizen Assist / ...|02/08/2021|02/08/2021|02/08/2021 10:18:...|02/08/2021 10:19:...|02/08/2021 10:19:...|02/08/2021 10:20:...|02/08/2021 10:27:...|                null|                null|                Fire|02/08/2021 10:53:...|FRANKLIN ST/FILBE...|San Francisco|            94123|      B04|         16|3233|               3|       3|            3|   true|               Alarm|             1|        ENGINE|                         1|                     4|                 2|              Marina|   210391034-E16|POINT (-122.42581...|\n",
      "| 210390767|   T19|      21017552|               Other|02/08/2021|02/08/2021|02/08/2021 08:50:...|02/08/2021 08:54:...|02/08/2021 08:55:...|02/08/2021 08:57:...|                null|                null|                null|                Fire|02/08/2021 09:02:...|CALL BOX: JOHN DA...|    Daly City|             null|      B09|         33|9922|               3|       3|            3|   true|                Fire|             1|         TRUCK|                         9|                  None|              None|                None|   210390767-T19|POINT (-122.46239...|\n",
      "| 210382984|   B05|      21017398|              Alarms|02/07/2021|02/07/2021|02/07/2021 09:18:...|02/07/2021 09:20:...|02/07/2021 09:21:...|02/07/2021 09:21:...|02/07/2021 09:25:...|                null|                null|                Fire|02/07/2021 09:35:...|2100 Block of FEL...|San Francisco|            94117|      B05|         12|4554|               3|       3|            3|  false|               Alarm|             1|         CHIEF|                         2|                     5|                 5|   Lone Mountain/USF|   210382984-B05|POINT (-122.45328...|\n",
      "| 210382403|   T05|      21017307|              Alarms|02/07/2021|02/07/2021|02/07/2021 05:24:...|02/07/2021 05:26:...|02/07/2021 05:26:...|02/07/2021 05:27:...|02/07/2021 05:30:...|                null|                null|                Fire|02/07/2021 05:50:...|1400 Block of GEA...|San Francisco|            94109|      B04|         38|3323|               3|       3|            3|  false|               Alarm|             1|         TRUCK|                         2|                     4|                 5|           Japantown|   210382403-T05|POINT (-122.42636...|\n",
      "| 210381978|   B10|      21017263|        Outside Fire|02/07/2021|02/07/2021|02/07/2021 03:09:...|02/07/2021 03:09:...|02/07/2021 03:11:...|02/07/2021 03:11:...|02/07/2021 03:11:...|                null|                null|                Fire|02/07/2021 03:39:...|500 Block of AMAD...|San Francisco|            94124|      B10|         25|6463|               3|       3|            3|  false|                Fire|             1|         CHIEF|                         5|                  10.0|                10|Bayview Hunters P...|   210381978-B10|POINT (-122.38299...|\n",
      "| 210381601|   T06|      21017206|              Alarms|02/07/2021|02/07/2021|02/07/2021 01:07:...|02/07/2021 01:09:...|02/07/2021 01:09:...|02/07/2021 01:10:...|02/07/2021 01:11:...|                null|                null|                Fire|02/07/2021 01:16:...|0 Block of SANCHE...|San Francisco|            94114|      B05|         06|5131|               3|       3|            3|  false|               Alarm|             1|         TRUCK|                         2|                     2|                 8| Castro/Upper Market|   210381601-T06|POINT (-122.43120...|\n",
      "| 210381356|  KM12|      21017173|    Medical Incident|02/07/2021|02/07/2021|02/07/2021 12:00:...|02/07/2021 12:00:...|02/07/2021 12:01:...|02/07/2021 12:02:...|02/07/2021 12:12:...|02/07/2021 12:27:...|02/07/2021 12:33:...|    Code 2 Transport|02/07/2021 01:05:...|2300 Block of 16T...|San Francisco|            94103|      B02|         29|5241|               2|       2|            2|  false|Non Life-threatening|             1|       PRIVATE|                         3|                     2|                10|             Mission|  210381356-KM12|POINT (-122.40952...|\n",
      "| 210380503|   E10|      21017065|              Alarms|02/07/2021|02/06/2021|02/07/2021 05:41:...|02/07/2021 05:42:...|02/07/2021 05:42:...|02/07/2021 05:44:...|02/07/2021 05:46:...|                null|                null|                Fire|02/07/2021 06:15:...|1400 Block of BAK...|San Francisco|            94115|      B05|         10|4262|               3|       3|            3|   true|               Alarm|             1|        ENGINE|                         2|                     5|                 5|           Japantown|   210380503-E10|POINT (-122.44301...|\n",
      "| 210380252|   E19|      21017021|              Alarms|02/07/2021|02/06/2021|02/07/2021 02:11:...|02/07/2021 02:12:...|02/07/2021 02:12:...|02/07/2021 02:14:...|02/07/2021 02:17:...|                null|                null|                Fire|02/07/2021 02:24:...|300 Block of ARBA...|San Francisco|            94132|      B08|         19|8582|               3|       3|            3|   true|               Alarm|             1|        ENGINE|                         1|                     8|                 7|           Lakeshore|   210380252-E19|POINT (-122.48306...|\n",
      "| 210372754|   E08|      21016911|              Alarms|02/06/2021|02/06/2021|02/06/2021 06:50:...|02/06/2021 06:51:...|02/06/2021 06:52:...|02/06/2021 06:53:...|02/06/2021 06:56:...|                null|                null|                Fire|02/06/2021 06:59:...|   0 Block of 6TH ST|San Francisco|            94103|      B03|         01|2251|               3|       3|            3|   true|               Alarm|             1|        ENGINE|                         2|                     3|                 6|     South of Market|   210372754-E08|POINT (-122.40902...|\n",
      "| 210370471|   B06|      21016646|      Structure Fire|02/06/2021|02/05/2021|02/06/2021 06:44:...|02/06/2021 06:46:...|02/06/2021 06:46:...|02/06/2021 06:48:...|02/06/2021 06:57:...|                null|                null|                Fire|02/06/2021 06:57:...|0 Block of DAKOTA ST|San Francisco|            94107|      B10|         37|2614|               3|       3|            3|  false|               Alarm|             1|         CHIEF|                         4|                    10|                10|        Potrero Hill|   210370471-B06|POINT (-122.39563...|\n",
      "| 210370398|   T07|      21016635|              Alarms|02/06/2021|02/05/2021|02/06/2021 05:33:...|02/06/2021 05:33:...|02/06/2021 05:33:...|02/06/2021 05:36:...|02/06/2021 05:40:...|                null|                null|                Fire|02/06/2021 05:42:...|800 Block of POTR...|San Francisco|            94110|      B10|         07|2553|               3|       3|            3|  false|               Alarm|             1|         TRUCK|                         2|                    10|                10|        Potrero Hill|   210370398-T07|POINT (-122.40672...|\n",
      "| 210370261|   T12|      21016610|              Alarms|02/06/2021|02/05/2021|02/06/2021 03:24:...|02/06/2021 03:27:...|02/06/2021 03:27:...|02/06/2021 03:29:...|02/06/2021 03:36:...|                null|                null|                Fire|02/06/2021 03:40:...|200 Block of UPPE...|San Francisco|            94117|      B05|         12|5165|               3|       3|            3|  false|               Alarm|             1|         TRUCK|                         3|                     5|                 8|      Haight Ashbury|   210370261-T12|POINT (-122.44517...|\n",
      "| 210362631|   T17|      21016433|              Alarms|02/05/2021|02/05/2021|02/05/2021 05:04:...|02/05/2021 05:06:...|02/05/2021 05:06:...|                null|                null|                null|                null|                Fire|02/05/2021 05:10:...|5800 Block of 3RD ST|San Francisco|            94124|      B10|         17|6537|               3|       3|            3|  false|               Alarm|             1|         TRUCK|                         3|                  10.0|                10|Bayview Hunters P...|   210362631-T17|POINT (-122.39472...|\n",
      "| 210360668|   E17|      21016151|        Outside Fire|02/05/2021|02/05/2021|02/05/2021 08:01:...|02/05/2021 08:05:...|02/05/2021 08:10:...|02/05/2021 08:10:...|02/05/2021 08:13:...|                null|                null|                Fire|02/05/2021 08:15:...|600 Block of INNE...|Hunters Point|            94124|      B10|         17|6663|               3|       3|            3|   true|                Fire|             1|        ENGINE|                         1|                    10|                10|Bayview Hunters P...|   210360668-E17|POINT (-122.37111...|\n",
      "| 210360399|    77|      21016122|    Medical Incident|02/05/2021|02/04/2021|02/05/2021 05:22:...|02/05/2021 05:24:...|02/05/2021 05:24:...|02/05/2021 05:25:...|                null|                null|                null|    Code 2 Transport|02/05/2021 05:28:...| 100 Block of 6TH ST|San Francisco|            94103|      B03|         01|2251|               3|       3|            3|   true|Potentially Life-...|             1|         MEDIC|                         3|                     3|                 6|     South of Market|    210360399-77|POINT (-122.40848...|\n",
      "| 210363081|   RC1|      21016489|    Medical Incident|02/05/2021|02/05/2021|02/05/2021 07:29:...|02/05/2021 07:29:...|02/05/2021 07:33:...|02/05/2021 07:34:...|                null|                null|                null|    Code 2 Transport|02/05/2021 07:35:...|  MISSION ST/10TH ST|San Francisco|            94103|      B02|         36|2341|               3|       E|            3|   true|Potentially Life-...|             1|RESCUE CAPTAIN|                         3|                     2|                 6|     South of Market|   210363081-RC1|POINT (-122.41590...|\n",
      "| 210390635|BLS841|      21017540|    Medical Incident|02/08/2021|02/08/2021|02/08/2021 08:09:...|02/08/2021 08:09:...|02/08/2021 08:09:...|02/08/2021 08:09:...|02/08/2021 08:49:...|                null|                null|               Other|02/08/2021 09:17:...| 0 Block of GROVE ST|San Francisco|            94102|      B02|         36|1552|               2|       2|            2|  false|                null|             1|         CHIEF|                         1|                     2|                 6|          Tenderloin|210390635-BLS841|POINT (-122.41739...|\n",
      "+----------+------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+-----------+----+----------------+--------+-------------+-------+--------------------+--------------+--------------+--------------------------+----------------------+------------------+--------------------+----------------+--------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:44:28.973343257Z",
     "start_time": "2023-09-08T14:44:22.901664047Z"
    }
   },
   "id": "57e247648d45825a"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T14:44:56.347295633Z",
     "start_time": "2023-09-08T14:44:56.173022224Z"
    }
   },
   "id": "22f509331d810d66"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write dataframe as table\n",
    "\n",
    "We can also write a dataframe into a table in mysql server. Spark need jdbc driver to write in mysql server.\n",
    "\n",
    "We can use two method:\n",
    "- method 1: df.write.format(\"jdbc\")\n",
    "- method 2: df.write.jdbc() \n",
    "\n",
    "In summary, both approaches can be used to achieve the same goal of writing a DataFrame to a JDBC data source, but the `df.write.jdbc()` method provides a more concise and convenient way to specify the necessary options for the operation. The choice between them depends on your preference and the complexity of your write operation.\n",
    "\n",
    "### An example with the method 1\n",
    "\n",
    "You can notice to specify the write method, we need to write many option lines."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f994b298209724c"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "tabName = \"employee\"\n",
    "sampleDF.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"driver\",driverName) \\\n",
    "  .option(\"url\", mysqlUrl) \\\n",
    "  .option(\"dbtable\", f\"{tabName}\") \\\n",
    "  .option(\"user\", f\"{uid}\") \\\n",
    "  .option(\"password\", f\"{pwd}\") \\\n",
    "  .mode(saveMode=\"overwrite\") \\\n",
    "  .save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T13:47:16.984884836Z",
     "start_time": "2023-09-11T13:47:16.386211980Z"
    }
   },
   "id": "2ea4de923cb68f95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### An example with the method 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81a96f792982879a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "mysqlProperties = {\n",
    "    \"user\": f\"{uid}\",\n",
    "    \"password\": f\"{pwd}\",\n",
    "    \"driver\": driverName,\n",
    "    \"rewriteBatchedStatements\": \"true\",\n",
    "    \"batchPerformanceWorkaround\": \"true\",\n",
    "    \"batchsize\": \"1000\"\n",
    "}\n",
    "sampleDF.write.jdbc(url=mysqlUrl, table=tabName, mode=\"overwrite\", properties=mysqlProperties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T13:30:31.195334001Z",
     "start_time": "2023-09-11T13:30:29.633042169Z"
    }
   },
   "id": "4c75432ec8e3baae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### append more rows into one table"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46fe9a1ed779210a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "columns = [\"id\", \"name\",\"age\",\"gender\"]\n",
    "data = [(5, \"JamesN\",30,\"M\"), (6, \"AnnN\",40,\"F\"),\n",
    "    (7, \"JeffN\",41,\"M\"),(8, \"JenniferN\",20,\"F\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T13:32:50.936260195Z",
     "start_time": "2023-09-11T13:32:50.893302367Z"
    }
   },
   "id": "1737a21b7bc1a7c5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+------+\n",
      "| id|     name|age|gender|\n",
      "+---+---------+---+------+\n",
      "|  5|   JamesN| 30|     M|\n",
      "|  6|     AnnN| 40|     F|\n",
      "|  7|    JeffN| 41|     M|\n",
      "|  8|JenniferN| 20|     F|\n",
      "+---+---------+---+------+\n"
     ]
    }
   ],
   "source": [
    "extraDF = spark.createDataFrame(data,schema=columns)\n",
    "extraDF.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T13:32:52.355283831Z",
     "start_time": "2023-09-11T13:32:51.964575347Z"
    }
   },
   "id": "2b6cf73a89b42ed1"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# insert extra rows into mysql server\n",
    "extraDF.write.jdbc(url=mysqlUrl, table=tabName, mode=\"append\", properties=mysqlProperties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T13:33:31.558842491Z",
     "start_time": "2023-09-11T13:33:30.819610246Z"
    }
   },
   "id": "fbbae66fc9938aa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimization of the write operation\n",
    "\n",
    "Writing a big dataframe may take long time. So we need to improve the speed of writing a DataFrame to a MySQL server. Here are some tips to improve the write performance:\n",
    "\n",
    "- **Use Batch Inserts**: Instead of inserting each row individually, batch your inserts. Use the `bulkCopyToTable` method from the MySQL Connector/J library to perform batch inserts, which can significantly improve write performance. The exact implementation will depend on the MySQL connector you are using.\n",
    "\n",
    "- **Tune the Number of Partitions**: Ensure that your DataFrame is properly partitioned. The number of partitions should match the degree of parallelism available in your cluster. You can repartition your DataFrame using the repartition() or coalesce() methods to control the number of partitions. If your DataFrame is very large, right partition number can reduce the size of individual write operations.\n",
    "\n",
    "- **Use JDBC Connection Properties**: Set appropriate JDBC connection properties to optimize the write operation. This includes tuning the `rewriteBatchedStatements` and `batchPerformanceWorkaround` options if using MySQL Connector/J.\n",
    "\n",
    "- **Choose the Right Write Mode**: Spark allows you to specify different write modes, such as \"overwrite,\" \"append,\" and \"ignore.\" Choose the write mode that fits your use case. For example, if you're appending data, use \"append\" mode to avoid overwriting existing data.\n",
    "\n",
    "- **Compression**: Enable compression when writing data to MySQL if your data is large. Compression can reduce the amount of data transferred and improve write performance. The level of compression can be controlled using JDBC connection properties.\n",
    "\n",
    "- **Partitioned Tables**: If possible, design your database tables to be partitioned based on columns that are frequently filtered or used in queries. This can significantly improve query performance.\n",
    "\n",
    "- **Indexing:** Properly index your MySQL tables to optimize write and read operations. However, be cautious with indexing, as it can impact write performance during inserts and updates.\n",
    "\n",
    "- **Optimize MySQL Configuration**: Ensure that your MySQL server is properly configured for write-intensive workloads. Tune MySQL's configuration parameters such as `innodb_buffer_pool_size`, `innodb_flush_log_at_trx_commit`, and others, based on your specific use case.\n",
    "\n",
    "- **Hardware Scaling**: If you have control over your infrastructure, consider scaling up your MySQL server by increasing CPU, memory, or using faster storage solutions like SSDs to improve write performance.\n",
    "\n",
    "\n",
    "In below example, \n",
    "- we first repartition the dataframe to 32 partition, because we have `4 worker`\n",
    "- We add below jdbc config \"rewriteBatchedStatements\": \"true\", \"batchPerformanceWorkaround\": \"true\", \"batchsize\": \"1000\"\n",
    "\n",
    "For a parquet file of 600 MB, and 5500519 rows, it takes 5 mins"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ebce2b11a91abbd"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/11 15:58:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+-----------+----+----------------+--------+-------------+-------+-------------+--------------+--------+--------------------------+----------------------+------------------+--------------------+-------------+--------------------+\n",
      "|CallNumber|UnitID|IncidentNumber|            CallType|  CallDate| WatchDate|        ReceivedDtTm|           EntryDtTm|        DispatchDtTm|        ResponseDtTm|         OnSceneDtTm|TransportDtTm|HospitalDtTm|CallFinalDisposition|       AvailableDtTm|             Address|         City|ZipcodeofIncident|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumberofAlarms|UnitType|Unitsequenceincalldispatch|FirePreventionDistrict|SupervisorDistrict|NeighborhoodDistrict|     Location|               RowID|\n",
      "+----------+------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+-----------+----+----------------+--------+-------------+-------+-------------+--------------+--------+--------------------------+----------------------+------------------+--------------------+-------------+--------------------+\n",
      "| 210391607|   E19|      21017645|              Alarms|02/08/2021|02/08/2021|02/08/2021 01:00:...|02/08/2021 01:01:...|02/08/2021 01:01:...|02/08/2021 01:03:...|02/08/2021 01:05:...|         null|        null|                Fire|02/08/2021 01:18:...|400 Block of SERR...|San Francisco|            94132|      B08|         19|8581|               3|       3|            3|   true|        Alarm|             1|  ENGINE|                         1|                     8|                 7|           Lakeshore|210391607-E19|POINT (-122.48045...|\n",
      "| 210391164|   T04|      21017596|              Alarms|02/08/2021|02/08/2021|02/08/2021 10:54:...|02/08/2021 10:56:...|02/08/2021 10:56:...|02/08/2021 10:57:...|02/08/2021 10:59:...|         null|        null|                Fire|02/08/2021 11:06:...|600 Block of LONG...|San Francisco|            94158|      B03|         04|2264|               3|       3|            3|  false|        Alarm|             1|   TRUCK|                         1|                     3|                 6|         Mission Bay|210391164-T04|POINT (-122.39227...|\n",
      "| 210391034|   E16|      21017578|Citizen Assist / ...|02/08/2021|02/08/2021|02/08/2021 10:18:...|02/08/2021 10:19:...|02/08/2021 10:19:...|02/08/2021 10:20:...|02/08/2021 10:27:...|         null|        null|                Fire|02/08/2021 10:53:...|FRANKLIN ST/FILBE...|San Francisco|            94123|      B04|         16|3233|               3|       3|            3|   true|        Alarm|             1|  ENGINE|                         1|                     4|                 2|              Marina|210391034-E16|POINT (-122.42581...|\n",
      "| 210390767|   T19|      21017552|               Other|02/08/2021|02/08/2021|02/08/2021 08:50:...|02/08/2021 08:54:...|02/08/2021 08:55:...|02/08/2021 08:57:...|                null|         null|        null|                Fire|02/08/2021 09:02:...|CALL BOX: JOHN DA...|    Daly City|             null|      B09|         33|9922|               3|       3|            3|   true|         Fire|             1|   TRUCK|                         9|                  None|              None|                None|210390767-T19|POINT (-122.46239...|\n",
      "| 210382984|   B05|      21017398|              Alarms|02/07/2021|02/07/2021|02/07/2021 09:18:...|02/07/2021 09:20:...|02/07/2021 09:21:...|02/07/2021 09:21:...|02/07/2021 09:25:...|         null|        null|                Fire|02/07/2021 09:35:...|2100 Block of FEL...|San Francisco|            94117|      B05|         12|4554|               3|       3|            3|  false|        Alarm|             1|   CHIEF|                         2|                     5|                 5|   Lone Mountain/USF|210382984-B05|POINT (-122.45328...|\n",
      "+----------+------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+-----------+----+----------------+--------+-------------+-------+-------------+--------------+--------+--------------------------+----------------------+------------------+--------------------+-------------+--------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sfPath=\"/home/pengfei/data_set/sf_fire/sf_fire_snappy.parquet\"\n",
    "df = spark.read.parquet(sfPath)\n",
    "df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T13:58:30.101786289Z",
     "start_time": "2023-09-11T13:58:25.031977981Z"
    }
   },
   "id": "66871a5843402030"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "5500519"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T15:27:35.872565607Z",
     "start_time": "2023-09-11T15:27:31.482358261Z"
    }
   },
   "id": "13b494800db938d1"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/11 15:59:45 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:45 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:45 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:46 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:46 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:46 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:47 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:47 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:47 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:47 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:48 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:48 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:48 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:49 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:49 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:50 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:50 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:50 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:51 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:51 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:51 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:52 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:52 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:52 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:53 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:53 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:53 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:54 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:54 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:54 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:55 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:55 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:55 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:55 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:56 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:56 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:56 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:57 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:57 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:58 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:58 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:58 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:59 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 15:59:59 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:00 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:00 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:00 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:01 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:01 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:01 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:01 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:02 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:02 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:02 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:03 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:03 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:03 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:04 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:04 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:05 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:05 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:05 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:06 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:00:19 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "df = df.repartition(32)\n",
    "print(df.rdd.getNumPartitions())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T14:01:27.615691786Z",
     "start_time": "2023-09-11T13:59:38.888305285Z"
    }
   },
   "id": "f3358a7b83d32743"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/11 16:03:24 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:24 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:25 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:25 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:25 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:25 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:26 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:26 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:26 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:27 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:27 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:27 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:27 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:28 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:28 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:28 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:29 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:29 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:29 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:30 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:30 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:30 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:31 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:31 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:31 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:32 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:32 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:32 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:32 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:33 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:33 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:34 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:34 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:34 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:34 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:35 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:35 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:35 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:36 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:36 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:36 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:37 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:37 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:37 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:38 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:38 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:38 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:39 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:39 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:39 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:40 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:40 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:40 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:41 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:41 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:41 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:42 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:42 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:42 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:42 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:43 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:43 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:43 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n",
      "23/09/11 16:03:44 WARN TaskMemoryManager: Failed to allocate a page (4194288 bytes), try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tabName = \"sf_fire\"\n",
    "mysqlProperties = {\n",
    "    \"user\": f\"{uid}\",\n",
    "    \"password\": f\"{pwd}\",\n",
    "    \"driver\": driverName,\n",
    "    \"rewriteBatchedStatements\": \"true\",\n",
    "    \"batchPerformanceWorkaround\": \"true\",\n",
    "    \"batchsize\": \"1000\"\n",
    "}\n",
    "df.write.jdbc(url=mysqlUrl, table=tabName, mode=\"overwrite\", properties=mysqlProperties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T14:08:40.139500739Z",
     "start_time": "2023-09-11T14:03:17.249542120Z"
    }
   },
   "id": "b63c2581af40815c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "78658a16b9e5cee1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
